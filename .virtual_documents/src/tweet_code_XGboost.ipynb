import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
import os
import string
import joblib
from text_loader.loader_new import DataLoader
import warnings 
warnings.filterwarnings("ignore")


loader_new = DataLoader("../data/Tweets.csv", True)


df = loader_new.load_data()
df.head(10)


df.shape


#Checking for labels
df['Party'].value_counts()


df[df['Tweet'].isna()]


#Checking if Tweet contains only strings
non_str_val = df[~df['Tweet'].apply(lambda x: isinstance(x, str))]


print(non_str_val)


#Since row is just one deleting this row
df = df[df['Tweet'].apply(lambda x: isinstance(x, str))]


df['Party'].value_counts()





df['Tweet'] = df['Tweet'].apply(loader_new.clean_text)
df.head()





df['Party'] = loader_new.label_encoder(df['Party'].tolist())
df.head()





X_train, X_test, y_train, y_test = train_test_split(df['Tweet'], df['Party'], stratify=df['Party'], test_size = 0.2 , random_state = 42)


X_train.shape,X_test.shape,y_train.shape,y_test.shape


y_train.value_counts(), y_test.value_counts()


X_train.head()





#Assigning tweets to X
X_train_vector = loader_new.vectorize_text(X_train.tolist(), fit=True)
X_test_vector = loader_new.vectorize_text(X_test.tolist(), fit=False)


X_train_vector.shape,y_train.shape,X_test_vector.shape,y_test.shape


model = xgb.XGBClassifier(use_label_encoder=False, eval_metric = 'logloss', max_depth = 10, objective='binary:logistic')
model.fit(X_train_vector, y_train)


preds = model.predict(X_test_vector)


pd.value_counts(preds)


X_train.shape, X_train_vector.shape


train_preds = model.predict(X_train_vector)


train_preds


X_train[26035]


pd.value_counts(train_preds)


preds.shape


acc = accuracy_score(y_test, preds)


print(acc)


print("Vectorizer loaded:", type(loader_new.vectorizer))
print("Has IDF:", hasattr(loader_new.vectorizer, "idf_"))
print("Vocabulary size:", len(loader_new.vectorizer.vocabulary_))


os.makedirs("model-inference-endpoint/saved_model", exist_ok=True)
os.makedirs("app/saved_model", exist_ok=True)

model.get_booster().save_model("model-inference-endpoint/saved_model/model.json")
#joblib.dump(model, "model-inference-endpoint/saved_model/model.pkl")
joblib.dump(loader_new.vectorizer, "model-inference-endpoint/saved_model/vectorizer.pkl")

model.get_booster().save_model("app/saved_model/model.json")
#joblib.dump(model, "app/saved_model/model.pkl")
joblib.dump(loader_new.vectorizer, "app/saved_model/vectorizer.pkl")


#!pip install scikit-learn==1.6.1


from text_loader.loader_new import DataLoader
import xgboost as xgb
import joblib

# Load model and vectorizer
booster = xgb.Booster()
booster.load_model("model-inference-endpoint/saved_model/model.json")

vectorizer = joblib.load("model-inference-endpoint/saved_model/vectorizer.pkl")
loader = DataLoader("", False)

# Step 1: Clean your tweet
tweet = "As a proud Pi Kappa Alpha I was delighted to celebrate the th Anniversary of our brotherhood on the HouseFloorâ€¦"
cleaned = loader.clean_text(tweet)

# Step 2: Vectorize
vec = vectorizer.transform([cleaned])

# Step 3: Convert to DMatrix
dmatrix = xgb.DMatrix(vec)

# Step 4: Predict using booster
prob_class_1 = booster.predict(dmatrix)[0]  # Republican = 1
pred = int(prob_class_1 >= 0.5)
label = "Republican" if pred == 1 else "Democrat"
confidence = round(prob_class_1 if pred == 1 else 1 - prob_class_1, 3)

print("Cleaned:", cleaned)
print("Prediction:", label)
print("Confidence:", confidence)



